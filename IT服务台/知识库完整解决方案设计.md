# 知识库完整解决方案设计

## 一、知识库整体架构

### 1.1 架构设计

```
┌─────────────────────────────────────────────────────────────┐
│                    知识库系统架构                              │
├─────────────────────────────────────────────────────────────┤
│                                                               │
│  应用层:                                                      │
│  ┌──────────────────────────────────────────────────────┐   │
│  │  知识库服务API (FastAPI)                              │   │
│  │  - 知识CRUD接口                                        │   │
│  │  - 知识检索接口                                        │   │
│  │  - 知识审核接口                                        │   │
│  │  - 知识统计接口                                        │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                               │
│  核心引擎层:                                                  │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │  检索引擎   │  │  向量引擎   │  │  管理引擎   │         │
│  │  ┌────────┐ │  │  ┌────────┐ │  │  ┌────────┐ │         │
│  │  │全文检索│ │  │  │向量化  │ │  │  │版本控制│ │         │
│  │  │语义检索│ │  │  │相似度  │ │  │  │审核流程│ │         │
│  │  │混合检索│ │  │  │重排序  │ │  │  │质量评分│ │         │
│  │  │Query改写│ │  │  │聚类    │ │  │  │权限管理│ │         │
│  │  └────────┘ │  │  └────────┘ │  │  └────────┘ │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
│                                                               │
│  存储层:                                                      │
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐         │
│  │  PostgreSQL │  │  Milvus     │  │  Elasticsearch│         │
│  │  结构化数据  │  │  向量存储   │  │  全文索引   │         │
│  │  ┌────────┐ │  │  ┌────────┐ │  │  ┌────────┐ │         │
│  │  │知识元数据│ │  │  │知识向量│ │  │  │知识内容│ │         │
│  │  │分类体系│ │  │  │FAQ向量 │ │  │  │分词索引│ │         │
│  │  │版本历史│ │  │  │工单向量│ │  │  │倒排索引│ │         │
│  │  │审核记录│ │  │  └────────┘ │  │  └────────┘ │         │
│  │  └────────┘ │  │             │  │             │         │
│  └─────────────┘  └─────────────┘  └─────────────┘         │
│  ┌─────────────┐  ┌─────────────┐                           │
│  │  Redis      │  │  MinIO/OSS  │                           │
│  │  缓存层      │  │  附件存储   │                           │
│  │  - 热点知识 │  │  - 文档    │                           │
│  │  - 检索结果 │  │  - 图片    │                           │
│  └─────────────┘  └─────────────┘                           │
└─────────────────────────────────────────────────────────────┘
```

### 1.2 数据流转

```
┌─────────────────────────────────────────────────────────┐
│  知识创建流程                                            │
├─────────────────────────────────────────────────────────┤
│                                                           │
│  1. 知识创建                                             │
│     ↓                                                    │
│  2. 结构化存储 (PostgreSQL)                              │
│     ├─ 知识元数据                                        │
│     ├─ 分类标签                                          │
│     └─ 创建人、时间                                      │
│     ↓                                                    │
│  3. 向量化 (Embedding)                                   │
│     ├─ 使用BGE-M3模型                                    │
│     ├─ 生成1024维向量                                    │
│     └─ 存入Milvus                                        │
│     ↓                                                    │
│  4. 全文索引 (Elasticsearch)                             │
│     ├─ 分词处理                                          │
│     ├─ 建立倒排索引                                      │
│     └─ 支持中文分词                                      │
│     ↓                                                    │
│  5. 审核流程                                             │
│     ├─ 待审核 → 审核中 → 已发布                          │
│     └─ 审核不通过 → 修改                                 │
│     ↓                                                    │
│  6. 发布上线                                             │
│     └─ 缓存预热 (Redis)                                  │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│  知识检索流程                                            │
├─────────────────────────────────────────────────────────┤
│                                                           │
│  1. 用户提问                                             │
│     ↓                                                    │
│  2. Query理解与改写                                      │
│     ├─ 意图识别                                          │
│     ├─ 同义词扩展                                        │
│     └─ 查询扩充                                          │
│     ↓                                                    │
│  3. 混合检索                                             │
│     ├─ 向量检索 (Milvus)          权重 70%              │
│     │  └─ Top 20 相似知识                                │
│     ├─ 全文检索 (Elasticsearch)    权重 30%              │
│     │  └─ Top 20 关键词匹配                              │
│     └─ 结果融合 (RRF算法)                                │
│     ↓                                                    │
│  4. 重排序 (Reranker)                                    │
│     ├─ 使用BGE-Reranker模型                              │
│     ├─ 精排Top 10                                        │
│     └─ 相关性打分                                        │
│     ↓                                                    │
│  5. 过滤与后处理                                         │
│     ├─ 权限过滤                                          │
│     ├─ 时效性过滤                                        │
│     └─ 去重                                              │
│     ↓                                                    │
│  6. 返回Top 5结果                                        │
│     └─ 包含知识内容、相关度、来源                        │
└─────────────────────────────────────────────────────────┘
```

---

## 二、数据模型设计

### 2.1 PostgreSQL结构化数据

#### 知识库表 (knowledge_base)

```sql
CREATE TABLE knowledge_base (
    id BIGSERIAL PRIMARY KEY,
    kb_id VARCHAR(50) UNIQUE NOT NULL COMMENT '知识库ID',
    title VARCHAR(200) NOT NULL COMMENT '知识标题',
    content TEXT NOT NULL COMMENT '知识内容（Markdown格式）',
    summary VARCHAR(500) COMMENT '摘要',

    -- 分类
    category_id BIGINT COMMENT '分类ID',
    category_path VARCHAR(500) COMMENT '分类路径（如：设备维护/打印机/驱动安装）',
    tags VARCHAR(200)[] COMMENT '标签数组',

    -- 适用对象
    target_audience VARCHAR(20) DEFAULT 'all' COMMENT '适用对象：all/user/engineer/admin',

    -- 问题描述
    problem_description TEXT COMMENT '问题现象',
    applicable_scene VARCHAR(500) COMMENT '适用场景',

    -- 解决方案
    solution_steps JSONB COMMENT '解决步骤（JSON数组）',
    cause_analysis TEXT COMMENT '原因分析',
    related_commands TEXT COMMENT '相关命令',

    -- 元数据
    author_id BIGINT COMMENT '作者ID',
    reviewer_id BIGINT COMMENT '审核人ID',
    status VARCHAR(20) DEFAULT 'draft' COMMENT '状态：draft/reviewing/published/archived',

    -- 质量指标
    quality_score FLOAT DEFAULT 0 COMMENT '质量评分（0-1）',
    view_count INT DEFAULT 0 COMMENT '查看次数',
    useful_count INT DEFAULT 0 COMMENT '有用次数',
    useless_count INT DEFAULT 0 COMMENT '无用次数',
    usefulness_rate FLOAT COMMENT '有用率',

    -- 关联
    related_tickets TEXT[] COMMENT '关联工单ID数组',
    related_knowledge TEXT[] COMMENT '关联知识ID数组',

    -- 版本
    version INT DEFAULT 1 COMMENT '版本号',
    parent_version_id BIGINT COMMENT '父版本ID（用于版本追溯）',

    -- 附件
    attachments JSONB COMMENT '附件列表（JSON数组）',

    -- 时效性
    expire_date DATE COMMENT '过期日期',
    is_expired BOOLEAN DEFAULT FALSE COMMENT '是否已过期',

    -- 时间戳
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    published_at TIMESTAMP COMMENT '发布时间',
    archived_at TIMESTAMP COMMENT '归档时间',

    -- 索引
    INDEX idx_category_id (category_id),
    INDEX idx_status (status),
    INDEX idx_target_audience (target_audience),
    INDEX idx_quality_score (quality_score),
    INDEX idx_view_count (view_count),
    INDEX idx_created_at (created_at),
    FULLTEXT INDEX idx_title_content (title, content)  -- MySQL 8.0支持
) COMMENT='知识库主表';
```

#### 知识分类表 (knowledge_categories)

```sql
CREATE TABLE knowledge_categories (
    id BIGSERIAL PRIMARY KEY,
    name VARCHAR(100) NOT NULL COMMENT '分类名称',
    slug VARCHAR(100) UNIQUE NOT NULL COMMENT '分类标识',
    description TEXT COMMENT '分类描述',
    parent_id BIGINT COMMENT '父分类ID',
    level INT DEFAULT 1 COMMENT '层级（1-3）',
    path VARCHAR(500) COMMENT '路径（如：1/2/3）',
    icon VARCHAR(100) COMMENT '图标',
    sort_order INT DEFAULT 0 COMMENT '排序',
    is_active BOOLEAN DEFAULT TRUE COMMENT '是否启用',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_parent_id (parent_id),
    INDEX idx_level (level),
    INDEX idx_slug (slug)
) COMMENT='知识分类表';

-- 初始化分类数据
INSERT INTO knowledge_categories (name, slug, level, path) VALUES
('设备维护', 'device-maintenance', 1, '1'),
('软件故障', 'software-issues', 1, '2'),
('系统配置', 'system-config', 1, '3'),
('权限管理', 'permission-management', 1, '4'),
('故障排查', 'troubleshooting', 1, '5');

-- 二级分类
INSERT INTO knowledge_categories (name, slug, parent_id, level, path) VALUES
('打印机', 'printer', 1, 2, '1/1'),
('网络设备', 'network-device', 1, 2, '1/2'),
('VDI客户端', 'vdi-client', 2, 2, '2/1'),
('办公软件', 'office-software', 2, 2, '2/2');
```

#### 知识审核表 (knowledge_reviews)

```sql
CREATE TABLE knowledge_reviews (
    id BIGSERIAL PRIMARY KEY,
    kb_id VARCHAR(50) NOT NULL COMMENT '知识库ID',
    reviewer_id BIGINT NOT NULL COMMENT '审核人ID',
    status VARCHAR(20) NOT NULL COMMENT '审核状态：pending/approved/rejected',
    comment TEXT COMMENT '审核意见',
    reviewed_at TIMESTAMP COMMENT '审核时间',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_kb_id (kb_id),
    INDEX idx_reviewer_id (reviewer_id),
    INDEX idx_status (status)
) COMMENT='知识审核表';
```

#### 知识版本表 (knowledge_versions)

```sql
CREATE TABLE knowledge_versions (
    id BIGSERIAL PRIMARY KEY,
    kb_id VARCHAR(50) NOT NULL COMMENT '知识库ID',
    version INT NOT NULL COMMENT '版本号',
    title VARCHAR(200) COMMENT '标题',
    content TEXT COMMENT '内容',
    change_log TEXT COMMENT '变更说明',
    changed_by BIGINT COMMENT '修改人ID',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    UNIQUE(kb_id, version),
    INDEX idx_kb_id (kb_id),
    INDEX idx_version (version)
) COMMENT='知识版本历史表';
```

#### 知识反馈表 (knowledge_feedback)

```sql
CREATE TABLE knowledge_feedback (
    id BIGSERIAL PRIMARY KEY,
    kb_id VARCHAR(50) NOT NULL COMMENT '知识库ID',
    user_id BIGINT NOT NULL COMMENT '用户ID',
    feedback_type VARCHAR(20) NOT NULL COMMENT '反馈类型：useful/useless/comment',
    rating INT COMMENT '评分（1-5）',
    comment TEXT COMMENT '反馈内容',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,

    INDEX idx_kb_id (kb_id),
    INDEX idx_user_id (user_id),
    INDEX idx_feedback_type (feedback_type)
) COMMENT='知识反馈表';
```

### 2.2 Milvus向量数据

#### Collection定义

```python
from pymilvus import CollectionSchema, FieldSchema, DataType

# 定义知识库向量Collection
def create_knowledge_collection():
    fields = [
        FieldSchema(name="id", dtype=DataType.INT64, is_primary=True, auto_id=False),
        FieldSchema(name="kb_id", dtype=DataType.VARCHAR, max_length=50),
        FieldSchema(name="title", dtype=DataType.VARCHAR, max_length=200),
        FieldSchema(name="category", dtype=DataType.VARCHAR, max_length=100),
        FieldSchema(name="target_audience", dtype=DataType.VARCHAR, max_length=20),
        FieldSchema(name="embedding", dtype=DataType.FLOAT_VECTOR, dim=1024),  # BGE-M3维度
        FieldSchema(name="created_at", dtype=DataType.INT64),
    ]

    schema = CollectionSchema(
        fields=fields,
        description="IT服务台知识库向量",
        enable_dynamic_field=True
    )

    # 创建collection
    from pymilvus import Collection
    collection = Collection(
        name="knowledge_base_vectors",
        schema=schema
    )

    # 创建索引（HNSW）
    index_params = {
        "metric_type": "IP",  # 内积（余弦相似度）
        "index_type": "HNSW",
        "params": {"M": 16, "efConstruction": 256}
    }
    collection.create_index(
        field_name="embedding",
        index_params=index_params
    )

    return collection
```

### 2.3 Elasticsearch全文索引

#### Index Mapping

```json
{
  "settings": {
    "number_of_shards": 3,
    "number_of_replicas": 1,
    "analysis": {
      "analyzer": {
        "ik_smart_analyzer": {
          "type": "custom",
          "tokenizer": "ik_smart",
          "filter": ["lowercase", "stop"]
        },
        "ik_max_word_analyzer": {
          "type": "custom",
          "tokenizer": "ik_max_word",
          "filter": ["lowercase", "stop"]
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "kb_id": {
        "type": "keyword"
      },
      "title": {
        "type": "text",
        "analyzer": "ik_max_word_analyzer",
        "search_analyzer": "ik_smart_analyzer",
        "fields": {
          "keyword": {
            "type": "keyword"
          }
        }
      },
      "content": {
        "type": "text",
        "analyzer": "ik_max_word_analyzer",
        "search_analyzer": "ik_smart_analyzer"
      },
      "summary": {
        "type": "text",
        "analyzer": "ik_smart_analyzer"
      },
      "category": {
        "type": "keyword"
      },
      "category_path": {
        "type": "text",
        "analyzer": "path_analyzer"
      },
      "tags": {
        "type": "keyword"
      },
      "target_audience": {
        "type": "keyword"
      },
      "status": {
        "type": "keyword"
      },
      "quality_score": {
        "type": "float"
      },
      "view_count": {
        "type": "integer"
      },
      "usefulness_rate": {
        "type": "float"
      },
      "created_at": {
        "type": "date"
      },
      "published_at": {
        "type": "date"
      }
    }
  }
}
```

---

## 三、核心功能实现

### 3.1 知识检索引擎（混合检索）

```python
# knowledge_retrieval_engine.py
from typing import List, Dict, Optional
import numpy as np
from pymilvus import Collection
from elasticsearch import Elasticsearch
from sentence_transformers import SentenceTransformer

class KnowledgeRetrievalEngine:
    """知识检索引擎"""

    def __init__(
        self,
        milvus_collection: Collection,
        es_client: Elasticsearch,
        embedding_model: SentenceTransformer,
        reranker_model: Optional[SentenceTransformer] = None
    ):
        self.milvus_collection = milvus_collection
        self.es_client = es_client
        self.embedding_model = embedding_model
        self.reranker_model = reranker_model

    async def search(
        self,
        query: str,
        top_k: int = 5,
        filters: Optional[Dict] = None,
        use_rerank: bool = True
    ) -> List[Dict]:
        """
        混合检索：向量检索 + 全文检索 + 重排序

        Args:
            query: 查询问题
            top_k: 返回结果数量
            filters: 过滤条件（如分类、受众等）
            use_rerank: 是否使用重排序

        Returns:
            List[Dict]: 检索结果列表
        """
        # 1. Query理解与改写
        enhanced_query = await self._enhance_query(query)

        # 2. 并行检索
        vector_results = await self._vector_search(enhanced_query, top_k=20, filters=filters)
        fulltext_results = await self._fulltext_search(enhanced_query, top_k=20, filters=filters)

        # 3. 结果融合（RRF算法）
        fused_results = self._reciprocal_rank_fusion(
            vector_results,
            fulltext_results,
            k=60
        )

        # 4. 重排序（可选）
        if use_rerank and self.reranker_model:
            fused_results = await self._rerank(query, fused_results, top_k=top_k * 2)

        # 5. 后处理
        final_results = await self._post_process(fused_results, top_k=top_k)

        return final_results

    async def _enhance_query(self, query: str) -> str:
        """Query增强：同义词扩展、拼写纠正等"""
        # 简单实现：同义词扩展
        synonyms = {
            "密码": ["密码", "口令", "登录密码"],
            "卡顿": ["卡顿", "慢", "性能差", "延迟高"],
            "重启": ["重启", "重新启动", "restart"],
        }

        enhanced_query = query
        for word, syns in synonyms.items():
            if word in query:
                enhanced_query += " " + " ".join(syns)

        return enhanced_query

    async def _vector_search(
        self,
        query: str,
        top_k: int = 20,
        filters: Optional[Dict] = None
    ) -> List[Dict]:
        """向量检索"""
        # 1. 向量化查询
        query_embedding = self.embedding_model.encode(query, normalize_embeddings=True)

        # 2. 构建过滤表达式
        filter_expr = self._build_filter_expr(filters)

        # 3. 向量搜索
        search_params = {
            "metric_type": "IP",
            "params": {"ef": 128}
        }

        results = self.milvus_collection.search(
            data=[query_embedding.tolist()],
            anns_field="embedding",
            param=search_params,
            limit=top_k,
            expr=filter_expr,
            output_fields=["kb_id", "title", "category"]
        )

        # 4. 格式化结果
        formatted_results = []
        for hits in results:
            for hit in hits:
                formatted_results.append({
                    "kb_id": hit.entity.get("kb_id"),
                    "title": hit.entity.get("title"),
                    "score": hit.score,
                    "source": "vector"
                })

        return formatted_results

    async def _fulltext_search(
        self,
        query: str,
        top_k: int = 20,
        filters: Optional[Dict] = None
    ) -> List[Dict]:
        """全文检索"""
        # 1. 构建ES查询
        must_clauses = [
            {
                "multi_match": {
                    "query": query,
                    "fields": ["title^3", "content^2", "summary"],  # title权重更高
                    "type": "best_fields",
                    "operator": "or",
                    "fuzziness": "AUTO"
                }
            }
        ]

        # 2. 添加过滤条件
        filter_clauses = []
        if filters:
            if filters.get("category"):
                filter_clauses.append({"term": {"category": filters["category"]}})
            if filters.get("target_audience"):
                filter_clauses.append({"term": {"target_audience": filters["target_audience"]}})

        # 3. 执行搜索
        es_query = {
            "query": {
                "bool": {
                    "must": must_clauses,
                    "filter": filter_clauses
                }
            },
            "size": top_k,
            "_source": ["kb_id", "title", "summary", "quality_score"]
        }

        response = self.es_client.search(
            index="knowledge_base",
            body=es_query
        )

        # 4. 格式化结果
        formatted_results = []
        for hit in response['hits']['hits']:
            formatted_results.append({
                "kb_id": hit['_source']['kb_id'],
                "title": hit['_source']['title'],
                "score": hit['_score'],
                "source": "fulltext"
            })

        return formatted_results

    def _reciprocal_rank_fusion(
        self,
        vector_results: List[Dict],
        fulltext_results: List[Dict],
        k: int = 60
    ) -> List[Dict]:
        """
        RRF (Reciprocal Rank Fusion) 算法融合结果

        RRF Score = Σ 1 / (k + rank_i)

        Args:
            k: 常数，通常取60
        """
        # 1. 构建结果字典
        all_results = {}

        # 2. 处理向量检索结果
        for rank, result in enumerate(vector_results, start=1):
            kb_id = result['kb_id']
            score = 1.0 / (k + rank)

            if kb_id not in all_results:
                all_results[kb_id] = {
                    "kb_id": kb_id,
                    "title": result['title'],
                    "vector_score": result['score'],
                    "rrf_score": 0,
                    "vector_rank": rank,
                    "fulltext_rank": None
                }
            all_results[kb_id]['rrf_score'] += score * 0.7  # 向量权重70%

        # 3. 处理全文检索结果
        for rank, result in enumerate(fulltext_results, start=1):
            kb_id = result['kb_id']
            score = 1.0 / (k + rank)

            if kb_id not in all_results:
                all_results[kb_id] = {
                    "kb_id": kb_id,
                    "title": result['title'],
                    "fulltext_score": result['score'],
                    "rrf_score": 0,
                    "vector_rank": None,
                    "fulltext_rank": rank
                }
            else:
                all_results[kb_id]['fulltext_rank'] = rank
                all_results[kb_id]['fulltext_score'] = result['score']

            all_results[kb_id]['rrf_score'] += score * 0.3  # 全文权重30%

        # 4. 按RRF得分排序
        fused_results = sorted(
            all_results.values(),
            key=lambda x: x['rrf_score'],
            reverse=True
        )

        return fused_results

    async def _rerank(
        self,
        query: str,
        candidates: List[Dict],
        top_k: int = 10
    ) -> List[Dict]:
        """
        重排序：使用Reranker模型精排

        使用BGE-Reranker模型，对候选结果进行精确相关性打分
        """
        if not candidates:
            return []

        # 1. 获取候选知识的完整内容（从PostgreSQL）
        kb_ids = [c['kb_id'] for c in candidates]
        knowledge_contents = await self._fetch_knowledge_contents(kb_ids)

        # 2. 构建query-document pairs
        pairs = []
        for candidate in candidates:
            kb_id = candidate['kb_id']
            content = knowledge_contents.get(kb_id, {}).get('content', '')
            pairs.append([query, content])

        # 3. Reranker打分
        scores = self.reranker_model.compute_score(pairs)

        # 4. 更新得分并重新排序
        for i, candidate in enumerate(candidates):
            candidate['rerank_score'] = scores[i]
            candidate['final_score'] = candidate['rrf_score'] * 0.3 + scores[i] * 0.7

        reranked_results = sorted(
            candidates,
            key=lambda x: x['final_score'],
            reverse=True
        )

        return reranked_results[:top_k]

    async def _post_process(
        self,
        results: List[Dict],
        top_k: int = 5
    ) -> List[Dict]:
        """后处理：权限过滤、去重、补充信息等"""
        # 1. 去重（基于kb_id）
        seen = set()
        unique_results = []
        for result in results:
            kb_id = result['kb_id']
            if kb_id not in seen:
                seen.add(kb_id)
                unique_results.append(result)

        # 2. 限制返回数量
        top_results = unique_results[:top_k]

        # 3. 补充完整信息（从PostgreSQL）
        kb_ids = [r['kb_id'] for r in top_results]
        full_knowledge = await self._fetch_knowledge_details(kb_ids)

        for result in top_results:
            kb_id = result['kb_id']
            if kb_id in full_knowledge:
                result.update(full_knowledge[kb_id])

        return top_results

    def _build_filter_expr(self, filters: Optional[Dict]) -> str:
        """构建Milvus过滤表达式"""
        if not filters:
            return ""

        expr_parts = []

        if filters.get("category"):
            expr_parts.append(f'category == "{filters["category"]}"')

        if filters.get("target_audience"):
            expr_parts.append(f'target_audience == "{filters["target_audience"]}"')

        return " && ".join(expr_parts)

    async def _fetch_knowledge_contents(self, kb_ids: List[str]) -> Dict:
        """从PostgreSQL获取知识内容"""
        # 实现略...
        pass

    async def _fetch_knowledge_details(self, kb_ids: List[str]) -> Dict:
        """从PostgreSQL获取知识详情"""
        # 实现略...
        pass


# 使用示例
async def example():
    from sentence_transformers import SentenceTransformer

    # 1. 初始化
    milvus_collection = Collection("knowledge_base_vectors")
    es_client = Elasticsearch(["http://localhost:9200"])
    embedding_model = SentenceTransformer("BAAI/bge-m3")
    reranker_model = SentenceTransformer("BAAI/bge-reranker-large")

    engine = KnowledgeRetrievalEngine(
        milvus_collection=milvus_collection,
        es_client=es_client,
        embedding_model=embedding_model,
        reranker_model=reranker_model
    )

    # 2. 搜索
    results = await engine.search(
        query="VDI客户端登录失败怎么办？",
        top_k=5,
        filters={"target_audience": "user"},
        use_rerank=True
    )

    # 3. 输出结果
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['title']}")
        print(f"   相关度: {result['final_score']:.4f}")
        print(f"   分类: {result['category']}")
        print()
```

---

### 3.2 知识管理服务

```python
# knowledge_management_service.py
from typing import List, Dict, Optional
from datetime import datetime
import hashlib

class KnowledgeManagementService:
    """知识管理服务"""

    def __init__(
        self,
        pg_client,  # PostgreSQL客户端
        milvus_collection,  # Milvus Collection
        es_client,  # Elasticsearch客户端
        embedding_model  # Embedding模型
    ):
        self.pg_client = pg_client
        self.milvus_collection = milvus_collection
        self.es_client = es_client
        self.embedding_model = embedding_model

    async def create_knowledge(self, knowledge_data: Dict) -> str:
        """
        创建知识

        步骤:
        1. 保存到PostgreSQL
        2. 向量化并存入Milvus
        3. 建立ES索引
        4. 触发审核流程
        """
        # 1. 生成知识ID
        kb_id = self._generate_kb_id(knowledge_data)

        # 2. 保存到PostgreSQL
        knowledge = {
            "kb_id": kb_id,
            "title": knowledge_data['title'],
            "content": knowledge_data['content'],
            "summary": knowledge_data.get('summary'),
            "category_id": knowledge_data.get('category_id'),
            "tags": knowledge_data.get('tags', []),
            "target_audience": knowledge_data.get('target_audience', 'all'),
            "solution_steps": knowledge_data.get('solution_steps'),
            "author_id": knowledge_data['author_id'],
            "status": "draft",
            "version": 1,
            "created_at": datetime.now()
        }

        await self.pg_client.insert("knowledge_base", knowledge)

        # 3. 向量化
        text_to_embed = f"{knowledge['title']}\n{knowledge['content']}"
        embedding = self.embedding_model.encode(text_to_embed, normalize_embeddings=True)

        # 4. 存入Milvus
        milvus_data = {
            "id": knowledge['id'],  # 数据库自增ID
            "kb_id": kb_id,
            "title": knowledge['title'],
            "category": knowledge.get('category'),
            "target_audience": knowledge['target_audience'],
            "embedding": embedding.tolist(),
            "created_at": int(knowledge['created_at'].timestamp())
        }

        self.milvus_collection.insert([milvus_data])

        # 5. 建立ES索引
        es_doc = {
            "kb_id": kb_id,
            "title": knowledge['title'],
            "content": knowledge['content'],
            "summary": knowledge.get('summary'),
            "category": knowledge.get('category'),
            "tags": knowledge.get('tags', []),
            "target_audience": knowledge['target_audience'],
            "status": "draft",
            "created_at": knowledge['created_at']
        }

        self.es_client.index(
            index="knowledge_base",
            id=kb_id,
            document=es_doc
        )

        # 6. 触发审核（异步）
        await self._trigger_review(kb_id, knowledge['author_id'])

        return kb_id

    async def update_knowledge(self, kb_id: str, update_data: Dict, operator_id: int) -> bool:
        """
        更新知识

        步骤:
        1. 保存版本历史
        2. 更新PostgreSQL
        3. 更新向量（重新向量化）
        4. 更新ES索引
        5. 重新审核
        """
        # 1. 获取当前版本
        current_version = await self.pg_client.get_one(
            "knowledge_base",
            {"kb_id": kb_id}
        )

        # 2. 保存版本历史
        version_data = {
            "kb_id": kb_id,
            "version": current_version['version'],
            "title": current_version['title'],
            "content": current_version['content'],
            "change_log": update_data.get('change_log', ''),
            "changed_by": operator_id,
            "created_at": datetime.now()
        }
        await self.pg_client.insert("knowledge_versions", version_data)

        # 3. 更新PostgreSQL
        new_version = current_version['version'] + 1
        update_data['version'] = new_version
        update_data['updated_at'] = datetime.now()
        update_data['status'] = 'reviewing'  # 重新审核

        await self.pg_client.update(
            "knowledge_base",
            {"kb_id": kb_id},
            update_data
        )

        # 4. 如果内容变更，重新向量化
        if 'title' in update_data or 'content' in update_data:
            updated_knowledge = await self.pg_client.get_one(
                "knowledge_base",
                {"kb_id": kb_id}
            )

            text_to_embed = f"{updated_knowledge['title']}\n{updated_knowledge['content']}"
            embedding = self.embedding_model.encode(text_to_embed, normalize_embeddings=True)

            # 更新Milvus
            self.milvus_collection.delete(expr=f'kb_id == "{kb_id}"')
            milvus_data = {
                "id": updated_knowledge['id'],
                "kb_id": kb_id,
                "title": updated_knowledge['title'],
                "embedding": embedding.tolist(),
                "created_at": int(updated_knowledge['created_at'].timestamp())
            }
            self.milvus_collection.insert([milvus_data])

        # 5. 更新ES
        self.es_client.update(
            index="knowledge_base",
            id=kb_id,
            doc=update_data
        )

        # 6. 触发审核
        await self._trigger_review(kb_id, operator_id)

        return True

    async def delete_knowledge(self, kb_id: str) -> bool:
        """
        删除知识（软删除）
        """
        # 1. PostgreSQL软删除
        await self.pg_client.update(
            "knowledge_base",
            {"kb_id": kb_id},
            {
                "status": "deleted",
                "deleted_at": datetime.now()
            }
        )

        # 2. Milvus删除
        self.milvus_collection.delete(expr=f'kb_id == "{kb_id}"')

        # 3. ES删除
        self.es_client.delete(
            index="knowledge_base",
            id=kb_id
        )

        return True

    async def publish_knowledge(self, kb_id: str, reviewer_id: int) -> bool:
        """
        发布知识（审核通过后）
        """
        # 1. 更新状态
        await self.pg_client.update(
            "knowledge_base",
            {"kb_id": kb_id},
            {
                "status": "published",
                "published_at": datetime.now(),
                "reviewer_id": reviewer_id
            }
        )

        # 2. 更新ES
        self.es_client.update(
            index="knowledge_base",
            id=kb_id,
            doc={"status": "published"}
        )

        # 3. 缓存预热（热门知识）
        await self._warm_up_cache(kb_id)

        return True

    async def record_feedback(self, kb_id: str, user_id: int, feedback_type: str) -> bool:
        """
        记录用户反馈
        """
        # 1. 保存反馈
        feedback = {
            "kb_id": kb_id,
            "user_id": user_id,
            "feedback_type": feedback_type,  # useful / useless
            "created_at": datetime.now()
        }
        await self.pg_client.insert("knowledge_feedback", feedback)

        # 2. 更新统计
        if feedback_type == "useful":
            await self.pg_client.increment("knowledge_base", {"kb_id": kb_id}, "useful_count")
        elif feedback_type == "useless":
            await self.pg_client.increment("knowledge_base", {"kb_id": kb_id}, "useless_count")

        # 3. 重新计算有用率
        knowledge = await self.pg_client.get_one("knowledge_base", {"kb_id": kb_id})
        total = knowledge['useful_count'] + knowledge['useless_count']
        if total > 0:
            usefulness_rate = knowledge['useful_count'] / total
            await self.pg_client.update(
                "knowledge_base",
                {"kb_id": kb_id},
                {"usefulness_rate": usefulness_rate}
            )

        return True

    def _generate_kb_id(self, knowledge_data: Dict) -> str:
        """生成知识ID"""
        text = f"{knowledge_data['title']}{knowledge_data['content']}{datetime.now().isoformat()}"
        hash_value = hashlib.md5(text.encode()).hexdigest()[:16]
        return f"KB{hash_value}"

    async def _trigger_review(self, kb_id: str, author_id: int):
        """触发审核流程（异步）"""
        # 实现略...
        pass

    async def _warm_up_cache(self, kb_id: str):
        """缓存预热"""
        # 实现略...
        pass
```

---

### 3.3 知识自动更新机制

```python
# knowledge_auto_update.py
from typing import List, Dict
from datetime import datetime, timedelta

class KnowledgeAutoUpdateService:
    """知识自动更新服务"""

    def __init__(
        self,
        pg_client,
        llm_service,  # LLM服务（用于生成知识）
        knowledge_mgmt_service  # 知识管理服务
    ):
        self.pg_client = pg_client
        self.llm_service = llm_service
        self.knowledge_mgmt_service = knowledge_mgmt_service

    async def auto_generate_from_tickets(self):
        """
        从工单自动生成知识

        策略:
        1. 识别高频问题（同类工单≥5次）
        2. 提取共性解决方案
        3. 自动生成知识草稿
        4. 提交审核
        """
        # 1. 查询最近7天的工单
        tickets = await self._get_recent_tickets(days=7)

        # 2. 聚类分析（找出相似问题）
        clusters = await self._cluster_tickets(tickets)

        # 3. 对每个簇生成知识
        for cluster in clusters:
            if len(cluster['tickets']) >= 5:  # 高频问题
                await self._generate_knowledge_from_cluster(cluster)

    async def _cluster_tickets(self, tickets: List[Dict]) -> List[Dict]:
        """聚类分析工单"""
        # 实现略（使用向量相似度聚类）
        pass

    async def _generate_knowledge_from_cluster(self, cluster: Dict):
        """从工单簇生成知识"""
        # 1. 提取工单信息
        ticket_descriptions = [t['description'] for t in cluster['tickets']]
        ticket_solutions = [t['solution'] for t in cluster['tickets'] if t.get('solution')]

        # 2. 调用LLM生成知识
        prompt = f"""
        请基于以下工单信息，生成一个知识库条目：

        问题描述：
        {chr(10).join(ticket_descriptions[:5])}  # 最多5个示例

        解决方案：
        {chr(10).join(ticket_solutions[:5])}

        请生成：
        1. 知识标题（简洁明确）
        2. 问题现象（通用描述）
        3. 解决步骤（步骤化）
        4. 适用场景

        输出JSON格式。
        """

        response = await self.llm_service.chat(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            response_format={"type": "json"}
        )

        knowledge_data = json.loads(response)

        # 3. 创建知识草稿
        await self.knowledge_mgmt_service.create_knowledge({
            **knowledge_data,
            "author_id": 0,  # 系统自动生成
            "status": "draft",
            "source": "auto_generated",
            "related_tickets": [t['id'] for t in cluster['tickets']]
        })

    async def detect_outdated_knowledge(self):
        """
        检测过时知识

        策略:
        1. 长期无人查看（>6个月且查看次数<10）
        2. 负面反馈率高（无用率>60%）
        3. 关联产品版本已停用
        """
        # 1. 查询所有已发布知识
        all_knowledge = await self.pg_client.get_all(
            "knowledge_base",
            {"status": "published"}
        )

        outdated_list = []

        for kb in all_knowledge:
            # 检查1：长期无人查看
            if kb['view_count'] < 10:
                days_since_published = (datetime.now() - kb['published_at']).days
                if days_since_published > 180:  # 6个月
                    outdated_list.append({
                        "kb_id": kb['kb_id'],
                        "reason": "长期无人查看",
                        "action": "archive"
                    })
                    continue

            # 检查2：负面反馈率高
            if kb.get('usefulness_rate') is not None:
                if kb['usefulness_rate'] < 0.4:  # 有用率<40%
                    outdated_list.append({
                        "kb_id": kb['kb_id'],
                        "reason": "负面反馈率高",
                        "action": "review"
                    })

        # 2. 批量处理
        for item in outdated_list:
            if item['action'] == 'archive':
                await self._archive_knowledge(item['kb_id'])
            elif item['action'] == 'review':
                await self._mark_for_review(item['kb_id'], item['reason'])

        return outdated_list

    async def _archive_knowledge(self, kb_id: str):
        """归档知识"""
        await self.pg_client.update(
            "knowledge_base",
            {"kb_id": kb_id},
            {
                "status": "archived",
                "archived_at": datetime.now()
            }
        )

    async def _mark_for_review(self, kb_id: str, reason: str):
        """标记需要审核"""
        await self.pg_client.insert("knowledge_reviews", {
            "kb_id": kb_id,
            "status": "pending",
            "comment": f"系统自动检测：{reason}",
            "created_at": datetime.now()
        })
```

---

## 四、知识库API接口设计

```python
# knowledge_api.py
from fastapi import APIRouter, Depends, HTTPException, Query
from typing import List, Optional

router = APIRouter(prefix="/api/knowledge", tags=["Knowledge"])

# ========== 知识检索 ==========

@router.get("/search")
async def search_knowledge(
    query: str = Query(..., description="查询问题"),
    category: Optional[str] = Query(None, description="分类筛选"),
    target_audience: Optional[str] = Query(None, description="受众筛选"),
    top_k: int = Query(5, ge=1, le=20, description="返回数量"),
    use_rerank: bool = Query(True, description="是否使用重排序")
):
    """
    搜索知识库

    支持向量检索+全文检索+重排序
    """
    filters = {}
    if category:
        filters['category'] = category
    if target_audience:
        filters['target_audience'] = target_audience

    results = await knowledge_retrieval_engine.search(
        query=query,
        top_k=top_k,
        filters=filters,
        use_rerank=use_rerank
    )

    return {
        "success": True,
        "data": results,
        "total": len(results)
    }

# ========== 知识管理 ==========

@router.post("/")
async def create_knowledge(knowledge_data: KnowledgeCreateRequest):
    """创建知识"""
    kb_id = await knowledge_mgmt_service.create_knowledge(knowledge_data.dict())
    return {"success": True, "kb_id": kb_id}

@router.put("/{kb_id}")
async def update_knowledge(
    kb_id: str,
    update_data: KnowledgeUpdateRequest,
    operator_id: int = Depends(get_current_user_id)
):
    """更新知识"""
    success = await knowledge_mgmt_service.update_knowledge(
        kb_id, update_data.dict(), operator_id
    )
    return {"success": success}

@router.delete("/{kb_id}")
async def delete_knowledge(kb_id: str):
    """删除知识"""
    success = await knowledge_mgmt_service.delete_knowledge(kb_id)
    return {"success": success}

@router.get("/{kb_id}")
async def get_knowledge(kb_id: str):
    """获取知识详情"""
    knowledge = await knowledge_mgmt_service.get_knowledge(kb_id)
    if not knowledge:
        raise HTTPException(status_code=404, detail="Knowledge not found")
    return {"success": True, "data": knowledge}

# ========== 知识审核 ==========

@router.post("/{kb_id}/review")
async def review_knowledge(
    kb_id: str,
    review_data: KnowledgeReviewRequest,
    reviewer_id: int = Depends(get_current_user_id)
):
    """审核知识"""
    if review_data.status == "approved":
        await knowledge_mgmt_service.publish_knowledge(kb_id, reviewer_id)
    else:
        await knowledge_mgmt_service.reject_knowledge(
            kb_id, reviewer_id, review_data.comment
        )
    return {"success": True}

# ========== 知识反馈 ==========

@router.post("/{kb_id}/feedback")
async def feedback_knowledge(
    kb_id: str,
    feedback_type: str = Query(..., regex="^(useful|useless)$"),
    user_id: int = Depends(get_current_user_id)
):
    """用户反馈（有用/无用）"""
    success = await knowledge_mgmt_service.record_feedback(
        kb_id, user_id, feedback_type
    )
    return {"success": success}

# ========== 知识统计 ==========

@router.get("/stats/overview")
async def get_knowledge_stats():
    """知识库统计概览"""
    stats = await knowledge_mgmt_service.get_stats()
    return {"success": True, "data": stats}

@router.get("/stats/popular")
async def get_popular_knowledge(
    limit: int = Query(10, ge=1, le=50)
):
    """热门知识Top N"""
    popular = await knowledge_mgmt_service.get_popular_knowledge(limit)
    return {"success": True, "data": popular}
```

---

## 五、技术选型总结

| 组件 | 技术选择 | 理由 |
|------|---------|------|
| **结构化存储** | PostgreSQL 14+ | JSONB支持、全文检索、事务 |
| **向量数据库** | Milvus 2.3+ | 高性能、分布式、易扩展 |
| **全文检索** | Elasticsearch 8.x | 中文分词、聚合分析 |
| **缓存** | Redis 7.x | 高性能、数据结构丰富 |
| **Embedding模型** | BGE-M3 | 中文效果好、1024维、通用性强 |
| **Reranker模型** | BGE-Reranker-Large | 精排效果好、速度快 |
| **应用框架** | FastAPI | 异步支持、自动文档 |
| **任务调度** | APScheduler | 轻量级、灵活 |

---

## 六、部署建议

### 6.1 硬件配置

```yaml
知识库服务器（推荐配置）:
  CPU: 16核+ (向量化、检索计算密集)
  内存: 64GB+ (Milvus需要大内存)
  存储: NVMe SSD 1TB+ (索引、向量数据)
  GPU: 不需要（Embedding推理可用CPU）

数据库服务器:
  PostgreSQL: 8核 32GB内存 500GB SSD
  Elasticsearch: 16核 64GB内存 1TB SSD（3节点集群）
  Milvus: 16核 64GB内存 500GB SSD
  Redis: 8核 16GB内存
```

### 6.2 性能指标

| 指标 | 目标值 |
|------|--------|
| **检索延迟** | P95 < 500ms |
| **检索准确率** | Top 5准确率 > 80% |
| **QPS** | 单机100+ QPS |
| **知识容量** | 支持10万+知识条目 |
| **并发用户** | 支持500+并发检索 |

---

*知识库解决方案设计完成，接下来将继续设计AI能力平台的其他部分...*
